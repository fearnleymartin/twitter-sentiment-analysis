{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Germanicus\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "C:\\Users\\Germanicus\\Anaconda3\\lib\\site-packages\\nltk\\twitter\\__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
      "  warnings.warn(\"The twython library has not been installed. \"\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from helpers import export_predictions\n",
    "from feature_repr import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from helpers import build_poly\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_data ():\n",
    "    \n",
    "    embeddings = load_embeddings ()\n",
    "    print (\"Embeddings loaded\")\n",
    "    positive_tweets, negative_tweets,test_tweets = load_tweets (False)\n",
    "    print (\"Tweets loaded\")\n",
    "    vocab_dict = load_vocab ()\n",
    "    print (\"Vocabulary loaded\")\n",
    "    positive_tweets_feature_repr = feature_representation_v2 (embeddings, positive_tweets, vocab_dict)\n",
    "    negative_tweets_feature_repr = feature_representation_v2 (embeddings,negative_tweets,vocab_dict)\n",
    "    test_tweets_feature_repr = feature_representation_v2 (embeddings,test_tweets,vocab_dict)\n",
    "    print (\"First feature representation achieved\")\n",
    "    pos_tweets_lexicon_features,neg_tweets_lexicon_features,test_tweets_lexicon_features=load_lexicon_features ()\n",
    "    print (\"Lexicon features loaded\")\n",
    "    pos_tweets_features = concatenate_features (positive_tweets_feature_repr,pos_tweets_lexicon_features)\n",
    "    neg_tweets_features = concatenate_features (negative_tweets_feature_repr,neg_tweets_lexicon_features)\n",
    "    test_tweets_features = concatenate_features (test_tweets_feature_repr,test_tweets_lexicon_features)\n",
    "    \n",
    "    X = np.vstack ((pos_tweets_features, neg_tweets_features))\n",
    "    Y = np.hstack ((np.ones (pos_tweets_features.shape [0]), -1 * np.ones (neg_tweets_features.shape [0])))\n",
    "    \n",
    "    return X, Y, test_tweets_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings loaded\n",
      "Tweets loaded\n",
      "Vocabulary loaded\n",
      "First feature representation achieved\n",
      "Lexicon features loaded\n"
     ]
    }
   ],
   "source": [
    "lucas_X, Y, test_X = generate_data ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generateCharList ():\n",
    "    \n",
    "    chars = {}\n",
    "    \n",
    "    fp = open ('train_pos.txt')\n",
    "    line = fp.readline ()\n",
    "    \n",
    "    while line:\n",
    "        \n",
    "        for char in line:\n",
    "            if char not in chars:\n",
    "                chars [char] = 1\n",
    "            else:\n",
    "                chars [char] += 1\n",
    "                \n",
    "        line = fp.readline ()\n",
    "        \n",
    "    fp.close ()\n",
    "    \n",
    "    fp = open ('train_neg.txt')\n",
    "    line = fp.readline ()\n",
    "    \n",
    "    while line:\n",
    "        \n",
    "        for char in line:\n",
    "            if char not in chars:\n",
    "                chars [char] = 1\n",
    "            else:\n",
    "                chars [char] += 1\n",
    "                \n",
    "        line = fp.readline ()\n",
    "        \n",
    "    fp.close ()\n",
    "    \n",
    "    return chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "characters = generateCharList ()\n",
    "characters = dict((k, v) for k, v in characters.items() if v >= 5 and v != 200000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chars = {}\n",
    "i = 0\n",
    "\n",
    "for k in characters.keys():\n",
    "    chars [k] = i\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "analyzer = SentimentIntensityAnalyzer ()\n",
    "\n",
    "def tweetToVector (tweet, chars):\n",
    "    \n",
    "    vector = [0] * (len (chars) + 2)\n",
    "    \n",
    "    for char in tweet:\n",
    "        if char in chars:\n",
    "            vector [chars [char]] += 1\n",
    "            \n",
    "    \"\"\"words = tweet.split (' ')\n",
    "    vector [len (chars)] = len (words)\n",
    "    m = 0\n",
    "    \n",
    "    for word in words:\n",
    "        m += len (word)\n",
    "        \n",
    "    m /= len (words)\n",
    "    vector [len (vector) - 1] = m\n",
    "    \n",
    "    polarity = analyzer.polarity_scores (tweet)\n",
    "    vector.append (polarity ['pos'])\n",
    "    vector.append (polarity ['neu'])\n",
    "    vector.append (polarity ['neg'])\n",
    "    vector.append (polarity ['compound'])\"\"\"\n",
    "        \n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generateVectors (chars):\n",
    "    \n",
    "    X = []\n",
    "    Y = []\n",
    "    \n",
    "    fp = open ('train_pos.txt', encoding='utf8')\n",
    "    line = fp.readline ()\n",
    "    \n",
    "    while line:\n",
    "        \n",
    "        X.append (tweetToVector (line, chars))\n",
    "        Y.append (1)\n",
    "                \n",
    "        line = fp.readline ()\n",
    "        \n",
    "    fp.close ()\n",
    "    \n",
    "    fp = open ('train_neg.txt', encoding='utf8')\n",
    "    line = fp.readline ()\n",
    "    \n",
    "    while line:\n",
    "        \n",
    "        X.append (tweetToVector (line, chars))\n",
    "        Y.append (-1)\n",
    "                \n",
    "        line = fp.readline ()\n",
    "        \n",
    "    fp.close ()\n",
    "    \n",
    "    return np.array (Y), np.array (X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y, moi_X = generateVectors (chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Germanicus\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:429: DataConversionWarning: Data with input dtype int32 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, _DataConversionWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ..., \n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler ()\n",
    "scaler.fit (moi_X)\n",
    "moi_X_standard = scaler.transform (moi_X)\n",
    "\n",
    "moi_X [:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 101)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.hstack ((lucas_X, moi_X))\n",
    "Y = moi_Y\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler ()\n",
    "scaler.fit (X)\n",
    "X_standard = scaler.transform (X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf_cnn = MLPClassifier (batch_size = 1)\n",
    "clf_cnn.fit (X_standard, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.7729  ,  0.770875,  0.7638  ,  0.76255 ,  0.75995 ])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score (clf_cnn, X_standard, Y, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def trainScore (Y, X, classifier):\n",
    "    \n",
    "    r = 0\n",
    "    \n",
    "    for i in range (X.shape [0]):\n",
    "        if classifier.predict (X [i, :].reshape (1, -1)) [0] == Y [i]:\n",
    "            r += 1\n",
    "            \n",
    "    return 1.0 * r / X.shape [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.812795"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainScore (moi_Y, X_standard, clf_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lexicon_pos = np.load ('pos_tweets_lexicon_features.npy')\n",
    "lexicon_neg = np.load ('neg_tweets_lexicon_features.npy')\n",
    "lexicon_X = np.vstack ((lexicon_pos, lexicon_neg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 6)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexicon_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_log = LogisticRegression ()\n",
    "clf_log.fit (moi_X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.7507 ,  0.74893])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score (clf_log, moi_X, Y, cv=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.hstack ((moi_X, lexicon_X, lucas_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler ()\n",
    "scaler.fit (X)\n",
    "tX = scaler.transform (X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=1e-05,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_log = LogisticRegression ()\n",
    "clf_log.fit (tX, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.75577,  0.75313])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score (clf_log, tX, Y, cv=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.757065"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainScore (Y, tX, clf_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
