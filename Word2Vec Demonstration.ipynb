{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec\n",
    "\n",
    "Serie of Word2Vec tries. This uses a custom class called Word2Vec, relying on gensim's word2vec."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Germanicus\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:840: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n",
      "C:\\Users\\Germanicus\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1015: UserWarning: Pattern library is not installed, lemmatization won't be available.\n",
      "  warnings.warn(\"Pattern library is not installed, lemmatization won't be available.\")\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "from word2vec import generateBin, Word2Vec\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from helpers import trainScore, testScore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing positive, negative and test tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pos = open ('train_pos.txt').readlines ()\n",
    "neg = open ('train_neg.txt').readlines ()\n",
    "test = open ('test_data.txt').readlines ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segmented\n",
    "\n",
    "Here we'll generate 2 word2vec models : one based on positive tweets, the other one on negative tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bin file pos_model.bin has been created\n",
      "Bin file neg_model.bin has been created\n"
     ]
    }
   ],
   "source": [
    "generateBin ('train_pos.txt', 'pos_model.bin', nbFeatures = 50)\n",
    "generateBin ('train_neg.txt', 'neg_model.bin', nbFeatures = 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating positive Word2Vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec Instantiation\n",
      "\tConverting Train Set...\n",
      "\t\tExtracting Features from Positive Tweets... [####################]    (100%)    ETA : 20:44:12\n",
      "\t\tExtracting Features from Negative Tweets... [####################]    (100%)    ETA : 20:44:17\n",
      "\tStandardizing...\n",
      "Terminated\n"
     ]
    }
   ],
   "source": [
    "pos_word2vec = Word2Vec ('pos_model.bin', pos, neg, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating negative Word2Vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec Instantiation\n",
      "\tConverting Train Set...\n",
      "\t\tExtracting Features from Positive Tweets... [####################]    (100%)    ETA : 20:44:28\n",
      "\t\tExtracting Features from Negative Tweets... [####################]    (100%)    ETA : 20:44:33\n",
      "\tStandardizing...\n",
      "Terminated\n"
     ]
    }
   ],
   "source": [
    "neg_word2vec = Word2Vec ('neg_model.bin', pos, neg, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenating into full train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_seg = np.hstack ((pos_word2vec.getX (), neg_word2vec.getX ()))\n",
    "Y_seg = pos_word2vec.getY ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Logistic Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_seg = LogisticRegression ()\n",
    "clf_seg.fit (X_seg, Y_seg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scoring on train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing Train Score [####################]    (100%)    ETA : 20:46:02\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7800947368421053"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainScore (X_seg, Y_seg, clf_seg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating test features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting Test Set\n",
      "\tExtracting Features from Test Tweets... [####################]    (100%)    ETA : 20:46:29\n",
      "\tStandardizing...\n",
      "Terminated\n",
      "Converting Test Set\n",
      "\tExtracting Features from Test Tweets... [####################]    (100%)    ETA : 20:46:30\n",
      "\tStandardizing...\n",
      "Terminated\n"
     ]
    }
   ],
   "source": [
    "test_X_seg = np.hstack ((pos_word2vec.convertTest (test), neg_word2vec.convertTest (test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scoring on test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing Test Score [####################]    (100%)    ETA : 20:46:44\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7665"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testScore (test_X_seg, clf_seg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single\n",
    "\n",
    "This time we won't make a distinction between positive and negative and make a single Word2Vec model from both train sets\n",
    "\n",
    "First, generating the full train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with (open ('train_all.txt', 'w', encoding = 'utf-8')) as f:\n",
    "    f.write (open ('train_pos.txt').read () + open ('train_neg.txt').read ())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating the single model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bin file single_model.bin has been created\n"
     ]
    }
   ],
   "source": [
    "generateBin ('train_all.txt', 'single_model.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the Word2Vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec Instantiation\n",
      "\tConverting Train Set...\n",
      "\t\tExtracting Features from Positive Tweets... [####################]    (100%)    ETA : 20:49:49\n",
      "\t\tExtracting Features from Negative Tweets... [####################]    (100%)    ETA : 20:49:54\n",
      "\tStandardizing...\n",
      "Terminated\n"
     ]
    }
   ],
   "source": [
    "single_word2vec = Word2Vec ('single_model.bin', pos, neg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Logistic Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_single = LogisticRegression ()\n",
    "clf_single.fit (single_word2vec.getX (), single_word2vec.getY ())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scoring on train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing Train Score [####################]    (100%)    ETA : 20:50:49\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7167736842105263"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainScore (single_word2vec.getX (), single_word2vec.getY (), clf_single)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating test features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting Test Set\n",
      "\tExtracting Features from Test Tweets... [####################]    (100%)    ETA : 20:51:34\n",
      "\tStandardizing...\n",
      "Terminated\n"
     ]
    }
   ],
   "source": [
    "test_X_single = single_word2vec.convertTest (test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scoring on test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing Test Score [####################]    (100%)    ETA : 20:51:45\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.715"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testScore (test_X_single, clf_single)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice how important it is to segmentate the models into positive and negative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Full Train\n",
    "\n",
    "We will now proceed to do the segmentation but on more tweets (800,000 instead of 190,000). We'll also use Multi-Layer Perceptron model to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pos_full = open ('train_pos_full.txt', encoding = 'utf-8').readlines () [:400000]\n",
    "neg_full = open ('train_neg_full.txt', encoding = 'utf-8').readlines () [:400000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the segmented models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bin file pos_full_model.bin has been created\n",
      "Bin file neg_full_model.bin has been created\n"
     ]
    }
   ],
   "source": [
    "generateBin ('train_pos_full.txt', 'pos_full_model.bin', nbFeatures = 50)\n",
    "generateBin ('train_neg_full.txt', 'neg_full_model.bin', nbFeatures = 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating features from the positive model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec Instantiation\n",
      "\tConverting Train Set...\n",
      "\t\tExtracting Features from Positive Tweets... [####################]    (100%)    ETA : 20:59:26\n",
      "\t\tExtracting Features from Negative Tweets... [####################]    (100%)    ETA : 20:59:47\n",
      "\tStandardizing...\n",
      "Terminated\n"
     ]
    }
   ],
   "source": [
    "pos_full_word2vec = Word2Vec ('pos_full_model.bin', pos_full, neg_full, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating features from the negative model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec Instantiation\n",
      "\tConverting Train Set...\n",
      "\t\tExtracting Features from Positive Tweets... [####################]    (100%)    ETA : 21:00:11\n",
      "\t\tExtracting Features from Negative Tweets... [####################]    (100%)    ETA : 21:00:32\n",
      "\tStandardizing...\n",
      "Terminated\n"
     ]
    }
   ],
   "source": [
    "neg_full_word2vec = Word2Vec ('neg_full_model.bin', pos_full, neg_full, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenating into train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_full_seg = np.hstack ((pos_full_word2vec.getX (), neg_full_word2vec.getX ()))\n",
    "Y_full_seg = pos_full_word2vec.getY ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Logistic Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_seg_full = LogisticRegression ()\n",
    "clf_seg_full.fit (X_full_seg, Y_full_seg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scoring on train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing Train Score [####################]    (100%)    ETA : 21:03:00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7805725"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainScore (X_full_seg, Y_full_seg, clf_seg_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting Test Set\n",
      "\tExtracting Features from Test Tweets... [####################]    (100%)    ETA : 21:03:05\n",
      "\tStandardizing...\n",
      "Terminated\n",
      "Converting Test Set\n",
      "\tExtracting Features from Test Tweets... [####################]    (100%)    ETA : 21:03:06\n",
      "\tStandardizing...\n",
      "Terminated\n"
     ]
    }
   ],
   "source": [
    "test_X_full_seg = np.hstack ((pos_full_word2vec.convertTest (test), neg_full_word2vec.convertTest (test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scoring on test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing Test Score [####################]    (100%)    ETA : 21:03:09\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7745"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testScore (test_X_full_seg, clf_seg_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "clf_seg_mlp_full = MLPClassifier ()\n",
    "clf_seg_mlp_full.fit (X_full_seg, Y_full_seg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scoring on train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing Train Score [####################]    (100%)    ETA : 21:11:15\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.83579875"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainScore (X_full_seg, Y_full_seg, clf_seg_mlp_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scoring on test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing Test Score [####################]    (100%)    ETA : 21:11:30\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8175"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testScore (test_X_full_seg, clf_seg_mlp_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting to Kaggle\n",
    "\n",
    "Importing true test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "true_test = open ('true_test_data.txt', encoding = 'utf-8').readlines ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating true test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting Test Set\n",
      "\tExtracting Features from Test Tweets... [####################]    (100%)    ETA : 21:12:37\n",
      "\tStandardizing...\n",
      "Terminated\n",
      "Converting Test Set\n",
      "\tExtracting Features from Test Tweets... [####################]    (100%)    ETA : 21:12:38\n",
      "\tStandardizing...\n",
      "Terminated\n"
     ]
    }
   ],
   "source": [
    "true_test_X_full_seg = np.hstack ((pos_full_word2vec.convertTest (true_test), neg_full_word2vec.convertTest (true_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing Predictions [####################]    (100%)    ETA : 21:12:42\n"
     ]
    }
   ],
   "source": [
    "from helpers import predict, exportPredictions\n",
    "\n",
    "pred = predict (true_test_X_full_seg, clf_seg_mlp_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exporting for Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "exportPredictions (pred, 'kaggle_submission')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
